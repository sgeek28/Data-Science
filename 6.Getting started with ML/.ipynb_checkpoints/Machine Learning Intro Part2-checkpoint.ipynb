{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two goals during training phase:\n",
    "- Learn from labelled data\n",
    "- Avoid overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Every input is associated with labelled data\n",
    "- label is y here\n",
    "- for given input assume apples. Apples(input) having many features like color, shape etc.\n",
    "- the function says yes(1) or No(0) for given input that whether it is apple or not?. So, it is discrete.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How we are going to represent our training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2/1.png\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- it's a m*n matrix where m is number of training examples and\n",
    "- n is number of features for each examples\n",
    "- $x^{(1)}$=<$x_{(1)}$,$x_{(2)}$,$x_{(3)}$,......$x_{(n)}$>  : n features for a training example\n",
    "- $x^{(i)}$=<$x^{(1)}$,$x^{(1)}$,$x^{(3)}$,......$x^{(m)}$>  : m training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output can be classified into two types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- output is continuous labelled \n",
    "- function will map X to Y\n",
    "- here input is $R^{n}$ means input having n features\n",
    "- output is R means Real number\n",
    "- example predicting stock price,house price.\n",
    "- goal is to reduce loss ie., error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- output is discrete labelled\n",
    "- function will here also map X to Y\n",
    "- here input is $R^{n}$ means input having n features\n",
    "- output will belong to any one class i.e. if input is [0,1,2,.. k]=[Apple,Mango,.....,Orange], then output will be either 0,1,2.... or k class.\n",
    "- goal is to reduce misclassification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2/2.png\" width=600 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2/3.png\" width=600 height=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- algorithm can be linear,logistic regression, SVM, Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One of the most promising challenges found with supervised learning algorithms\n",
    "- Few model fits well with training data but doesn't be good for test set\n",
    "- Orange line represents such model\n",
    "- Similarly other model they are good for test set\n",
    "- Blue line represents such model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2/4.png\" width=600 height=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applications of Supervised Learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2/5.png\" width=600 height=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It has no supervision, no labelled data i.e. only X no Y\n",
    "- It has data in form of clusters\n",
    "- It tries to find patterns to group data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2/6.png\" width=600 height=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for e.g., we have tweets as input .\n",
    "- some people will upvote it and some will downvote\n",
    "- we can use words tweeted by people who downvoted it or those who are sad\n",
    "- similaryly we use good words tweeted by people who upvoted it or who were happy\n",
    "- then we can cluster them in two diff groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we have data points unlabelled and we try to label some data\n",
    "- assume we have 10 million data points. Even if we give 1 rs to someone to label 1 datapoint, it will be 10 million\n",
    " rupees.\n",
    "- for e.g., we can have tweets and we want to label them , then we can cluster one group with good emojis\n",
    " and other with sad emojis forming two clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2/7.png\" width=600 height=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applications of unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Object segmentation\n",
    "- Automatic labelling\n",
    "- Similarity Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- example: how do we learn bicycle? answer is by more and more practising.\n",
    "- Reinforcment learnig works similar way.\n",
    "- Can be used in games like maria, cartpoler etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two componets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Agent : that interacts with the environment\n",
    "- State : the parameters used to define environment is state. for e.g., in cart polar we have coordinate\n",
    "  x,y then velocity v, angular velocity of rod as a. All these are states.\n",
    "- Agent interacts with environment through action. Action is a part of set of Actions.\n",
    "- Performing action changes state of agent in environment. State is part of set of States.\n",
    "- In return evnironment gives +ve/-ve rewards to agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2/8.png\" width=600 height=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- to maximize rewards over all timestamps ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Game Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2/9.png\" width=600 height=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- to find best action in a given state using deep q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
